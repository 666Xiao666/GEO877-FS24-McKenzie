{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import of used packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and clean data\n",
    "\n",
    "We downloaded CoGo bicycle trip data from the CoGoBike website. The data is available as CSV for each month. For our project, we use the bicycle trips of the following months and years:\n",
    "  -- July 2020\n",
    "  -- December 2020\n",
    "  -- July 2021\n",
    "  -- December 2021\n",
    "  -- July 2022\n",
    "  -- December 2022\n",
    "  -- July  2023\n",
    "  -- December 2023\n",
    "\n",
    "Data source: https://cogo-sys-data.s3.amazonaws.com/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in and clean data, Calculate trip durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From a total number of 37203 entries, 2434 entries (6.542 %) have been removed.\n"
     ]
    }
   ],
   "source": [
    "class Cogo_Tripdata:\n",
    "    def __init__(self, input_path, output_path):\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "        self.count_original = 0 \n",
    "        self.count_clean = 0\n",
    "        self.filelist = os.listdir(input_path)\n",
    "\n",
    "    # Read the original csv-bike trip data and add each row into a dictionary, wich then are stored within a list\n",
    "    def read_csv(self, file_path):\n",
    "        data = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            csv_reader = csv.DictReader(file)\n",
    "            for row in csv_reader:\n",
    "                data.append(row)\n",
    "        return data\n",
    "    \n",
    "    # List of rows is converted back into csv with the given attributes as headers\n",
    "    def write_csv(self, file_path, data, fieldnames):\n",
    "        with open(file_path, 'w', newline='') as file:\n",
    "            csv_writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            csv_writer.writeheader()\n",
    "            csv_writer.writerows(data)\n",
    "\n",
    "    # Starting and ending trip timestamps are stored as floats. Those are converted into date format to calculate the trip durations.\n",
    "    # Trip durations are calculated in minutes and added as new attribute 'trip_duration [min]'\n",
    "    def calculate_trip_duration(self, row):\n",
    "        start = datetime.strptime(row['started_at'], '%Y-%m-%d %H:%M:%S')\n",
    "        end = datetime.strptime(row['ended_at'], '%Y-%m-%d %H:%M:%S')  \n",
    "        trip_duration = int((end - start).total_seconds() / 60) \n",
    "        row['trip_duration [min]'] = trip_duration \n",
    "        return row\n",
    "\n",
    "    # The original data consists of corrupt data. To get reliable results:\n",
    "    # We set a maximum trip duration of 100 min (based on histogram plots of all trip durations).\n",
    "    # We delete trips that lasts less than 10 minutes AND end at the same coordinates as they start\n",
    "    # We delete trips that have no coordinate values\n",
    "    def clean_data(self, data):\n",
    "        max_duration = 100\n",
    "        min_duration = 10\n",
    "        cleaned_data = []\n",
    "\n",
    "        for row in data:\n",
    "            if ((row['trip_duration [min]'] < max_duration and\n",
    "                row['start_lat'] and row['start_lng'] and row['end_lat'] and row['end_lng']) \n",
    "                and not\n",
    "                (row['trip_duration [min]'] < min_duration and row['start_lat'] == row['end_lat'] and row['start_lng'] == row['end_lng'])):\n",
    "                cleaned_data.append(row)\n",
    "\n",
    "        return cleaned_data\n",
    "\n",
    "    # Reads in, writes, calculates trip distances and cleans data for each of the original csv-files. \n",
    "    # Storing the output files in a new folder, which we use for further processing. \n",
    "    def process_files(self):\n",
    "        for f in self.filelist:\n",
    "            source = os.path.join(self.input_path, f)\n",
    "            data = self.read_csv(source)\n",
    "            self.count_original += len(data)\n",
    "\n",
    "            data_with_trip_duration = [self.calculate_trip_duration(row) for row in data]\n",
    "\n",
    "            cleaned_data = self.clean_data(data_with_trip_duration)\n",
    "            self.count_clean += len(cleaned_data)\n",
    "\n",
    "            output_file = os.path.join(self.output_path, \"cleaned\" + f)\n",
    "            self.write_csv(output_file, cleaned_data, fieldnames=data[0].keys())\n",
    "\n",
    "        removed = self.count_original - self.count_clean\n",
    "        share_removed = round((removed / self.count_original) * 100, 3)\n",
    "\n",
    "        print(f\"From a total number of {self.count_original} entries, {removed} entries ({share_removed} %) have been removed.\")\n",
    "\n",
    "input_path = \"/Users/benedikt/Documents/GitHub/GEO877-FS24-McKenzie/data/original_data/\"\n",
    "output_path = \"/Users/benedikt/Documents/GitHub/GEO877-FS24-McKenzie/data/cleaned_data/\"\n",
    "cogo_datacleaning = Cogo_Tripdata(input_path, output_path)\n",
    "cogo_datacleaning.process_files()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
